#!/usr/bin/env python3
"""
Script de prueba para verificar la configuraciÃ³n de Ollama
"""

import asyncio
import sys
import os

# Agregar el directorio actual al path para importar servicios
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.ollama_service import ollama_service


async def test_ollama():
    """Prueba la conectividad y funcionalidad de Ollama"""
    
    print("ğŸ” Verificando configuraciÃ³n de Ollama...")
    print(f"   Base URL: {ollama_service.base_url}")
    print(f"   Modelo: {ollama_service.model_name}")
    print()
    
    # Verificar salud de Ollama
    print("ğŸ¥ Verificando salud del servicio...")
    health = await ollama_service._check_ollama_health()
    if health:
        print("   âœ… Ollama estÃ¡ ejecutÃ¡ndose")
    else:
        print("   âŒ Ollama no estÃ¡ disponible")
        print("\nğŸ’¡ Soluciones:")
        print("   1. Instala Ollama desde https://ollama.ai")
        print("   2. Ejecuta: ollama serve")
        print("   3. Verifica que el puerto 11434 estÃ© libre")
        return False
    
    # Verificar modelo
    print("\nğŸ¤– Verificando modelo...")
    model_available = await ollama_service._ensure_model_available()
    if model_available:
        print(f"   âœ… Modelo {ollama_service.model_name} disponible")
    else:
        print(f"   âŒ Modelo {ollama_service.model_name} no disponible")
        print(f"\nğŸ’¡ SoluciÃ³n: ollama pull {ollama_service.model_name}")
        return False
    
    # Prueba de generaciÃ³n
    print("\nğŸ’¬ Probando generaciÃ³n de respuesta...")
    try:
        response = await ollama_service.generate_response(
            user_question="Hola, Â¿cÃ³mo estÃ¡s?",
            chatbot_name="Asistente de Prueba"
        )
        
        if response.get("success"):
            print("   âœ… GeneraciÃ³n exitosa")
            print(f"   Respuesta: {response.get('response', '')[:100]}...")
        else:
            print("   âŒ Error en generaciÃ³n")
            print(f"   Error: {response.get('error', 'Desconocido')}")
            return False
            
    except Exception as e:
        print(f"   âŒ ExcepciÃ³n durante generaciÃ³n: {str(e)}")
        return False
    
    # Prueba de tÃ­tulo
    print("\nğŸ“ Probando generaciÃ³n de tÃ­tulo...")
    try:
        title = await ollama_service.generate_title_for_conversation(
            "Â¿CuÃ¡les son las mejores prÃ¡cticas de programaciÃ³n?"
        )
        print(f"   âœ… TÃ­tulo generado: {title}")
    except Exception as e:
        print(f"   âŒ Error generando tÃ­tulo: {str(e)}")
    
    print("\nğŸ‰ Â¡Todas las pruebas completadas exitosamente!")
    print("\nğŸš€ El chatbot estÃ¡ listo para usar Ollama local")
    return True


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª PRUEBA DE CONFIGURACIÃ“N OLLAMA")
    print("=" * 60)
    
    success = asyncio.run(test_ollama())
    
    if success:
        sys.exit(0)
    else:
        sys.exit(1)