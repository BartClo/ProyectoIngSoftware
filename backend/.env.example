# Variables de entorno para el Chatbot USS
# IMPORTANTE: Copia este archivo como .env y completa con tus valores reales

# === CONFIGURACIÓN DE BASE DE DATOS ===
# Formato: postgresql://usuario:contraseña@host:puerto/nombre_base_datos
DATABASE_URL=postgresql://postgres:TU_PASSWORD@localhost:5432/mi_proyecto

# === CONFIGURACIÓN DE IA LOCAL (OLLAMA) ===
# URL base de Ollama (por defecto localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
# Modelo de Ollama a usar (por defecto llama3.2)
OLLAMA_MODEL=llama3.2

# === CONFIGURACIÓN DE GEMINI IA (OPCIONAL - COMENTADO) ===
# API Key de Google Gemini 2.0 Flash para el chatbot
# GEMINI_API_KEY=tu_gemini_api_key_aqui
# GEMINI_MODEL=gemini-2.0-flash-exp

# === CONFIGURACIÓN PINECONE ===
# API Key y configuración de Pinecone para RAG
PINECONE_API_KEY=tu_pinecone_api_key_aqui
PINECONE_ENVIRONMENT=us-east1-gcp

# === CONFIGURACIÓN HUGGING FACE ===
# Token para modelos de embeddings (opcional)
HUGGINGFACE_API_TOKEN=tu_huggingface_token_aqui

# === CONFIGURACIÓN JWT ===
# Clave secreta para tokens JWT (genera una clave segura)
SECRET_KEY=tu_clave_secreta_muy_segura_aqui

# Tiempo de expiración de tokens en minutos
ACCESS_TOKEN_EXPIRE_MINUTES=120

# === CONFIGURACIÓN DE ARCHIVOS ===
# Tamaño máximo de archivos en MB
MAX_FILE_SIZE_MB=50

# Extensiones permitidas para documentos
ALLOWED_EXTENSIONS=pdf,docx,txt,md

# Carpeta de uploads
UPLOAD_FOLDER=./uploads

# === CONFIGURACIÓN RAG ===
# Modelo de embeddings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Configuración de chunks
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5

# === CONFIGURACIÓN DEL SERVIDOR ===
# Puerto del servidor (opcional, por defecto 8000)
PORT=8000

# Entorno de ejecución
ENVIRONMENT=development
